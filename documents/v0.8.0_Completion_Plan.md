# v0.8.0 Completion Plan

## Executive Summary

**Status**: Pipeline restructure complete ✅ (December 3, 2025)
**Remaining Work**: Four optimization/correctness improvements
**Target Release**: Mid-December 2025
**Estimated Effort**: 14-22 working days

---

## What's Been Completed

### Pipeline Restructure (feature/pipeline-structure) ✅

From the recent merge:
- **Stage-based architecture** with `PipelineStage` trait
- **Orchestrators** for single-end and paired-end processing
- **500-line merge gating** achieved for all new modules
- **Dead code removal**: ~1,223 lines eliminated
- **15% performance improvement** vs v0.7.0 baseline
- **Zero behavioral regressions** verified on HG002 10K dataset

**Key Files Created**:
- `src/pipelines/linear/orchestrator/` - Pipeline coordination (137-423 lines/file)
- `src/pipelines/linear/stages/` - Stage wrappers (190-324 lines/file)
- All modules under 500-line target

---

## Remaining v0.8.0 Work (from README)

The public roadmap (README.md lines 324-328) lists four items:

| Priority | Item | Current State | Target | Public Visibility |
|----------|------|---------------|--------|-------------------|
| **#1** | **Pairing Accuracy** | 94.14% properly paired | 97%+ | HIGH - User-facing correctness issue |
| **#2** | **Performance** | ~79% of BWA-MEM2 | 85-90% | HIGH - Benchmark comparison in README |
| **#3** | **Memory** | ~32 GB peak | ~24 GB | MEDIUM - Resource efficiency |
| **#4** | **Threading** | Unknown utilization | Better balance | MEDIUM - Multicore efficiency |

---

## Phase 1: Establish Baselines

**Duration**: 1-2 days
**Goal**: Get accurate measurements before optimizing

### 1.1 Performance Profiling

**Task**: Measure stage-level timing breakdown

```bash
# Instrumented run on 10K HG002 dataset
RUSTFLAGS="-C force-frame-pointers=yes" cargo build --release
perf record -F 999 -g ./target/release/ferrous-align mem \
    -t 16 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > /dev/null
perf report --stdio > perf_baseline.txt

# Flamegraph generation
perf script | stackcollapse-perf.pl | flamegraph.pl > flamegraph.svg
```

**Stage-level timing**: Add logging to orchestrators
```rust
let start = Instant::now();
let seeds = self.seeder.process(batch, &self.ctx)?;
log::debug!("Seeding: {:.2}ms", start.elapsed().as_secs_f64() * 1000.0);
```

**Deliverable**: `documents/benchmarks/v0.8.0_baseline_profile.md`
- Time spent per stage (%)
- Hot functions identified
- SIMD utilization estimate

### 1.2 Memory Profiling

**Task**: Identify peak allocation points

```bash
# Massif profiling
valgrind --tool=massif --massif-out-file=massif.out \
    ./target/release/ferrous-align mem -t 1 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > /dev/null
ms_print massif.out > memory_baseline.txt

# Heaptrack (if available)
heaptrack ./target/release/ferrous-align mem -t 16 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > /dev/null
heaptrack_print heaptrack.*.gz > heaptrack_baseline.txt
```

**Deliverable**: `documents/benchmarks/v0.8.0_memory_profile.md`
- Peak memory usage breakdown
- Per-stage allocation patterns
- Batch size vs memory trade-offs

### 1.3 Threading Profiling

**Task**: Measure core utilization and contention

```bash
# perf stat for core utilization
perf stat -e cycles,instructions,cache-references,cache-misses,branch-misses \
    ./target/release/ferrous-align mem -t 16 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > /dev/null

# Thread timeline visualization
perf record -g -e sched:sched_switch ./target/release/ferrous-align mem -t 16 ...
```

**Deliverable**: `documents/benchmarks/v0.8.0_threading_profile.md`
- CPU utilization per thread
- Lock contention points
- Work-stealing efficiency

### 1.4 Pairing Accuracy Baseline

**Task**: Identify which reads are mis-paired

```bash
# Generate comparable SAM outputs
bwa-mem2 mem -t 16 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > bwa_mem2.sam
ferrous-align mem -t 16 /data/ref.fa /data/10k_R1.fq /data/10k_R2.fq > ferrous.sam

# Compare pairing decisions
samtools view -f 2 bwa_mem2.sam | cut -f1 | sort > bwa_paired.txt
samtools view -f 2 ferrous.sam | cut -f1 | sort > ferrous_paired.txt
comm -3 bwa_paired.txt ferrous_paired.txt > mismatched_pairs.txt
```

**Deliverable**: `documents/analysis/v0.8.0_pairing_discrepancies.md`
- List of mis-paired read IDs
- Pattern analysis (genomic regions, read characteristics)
- Suspected root causes

**Acceptance Criteria**:
- [ ] Performance profile complete with stage timing breakdown
- [ ] Memory profile shows peak usage and allocation hotspots
- [ ] Threading profile identifies utilization bottlenecks
- [ ] Pairing discrepancy analysis identifies root causes

---

## Phase 2: Pairing Accuracy (Priority #1)

**Duration**: 3-5 days
**Goal**: Close the 3pp gap (94.14% → 97%+)

### Why First?

Correctness is more important than performance. Users trust alignment results for downstream analysis (variant calling, etc.). A 3pp gap is acceptable for alpha but not for beta/production.

### Root Cause Investigation

The Pipeline Restructure v0.8 Plan (lines 36-47) identifies suspected causes:

1. **Seeding stage** - Different SMEM generation
2. **Chaining stage** - Different chain selection/tie-breaking
3. **Extension stage** - Different extension boundaries

### Investigation Strategy

#### 2.1 Compare Intermediate Outputs

Create debug mode that dumps intermediate stages:

```rust
// In orchestrator, add debug flag
if opts.debug_stages {
    dump_seeds_to_file(&seeds, "ferrous_seeds.txt");
    dump_chains_to_file(&chains, "ferrous_chains.txt");
    dump_alignments_to_file(&alignments, "ferrous_alignments.txt");
}
```

**Compare with BWA-MEM2** (if possible, or infer from behavior):
- Do we generate the same SMEMs for the same read?
- Do we select the same chains?
- Do extension boundaries match?

#### 2.2 Focus on Mis-Paired Reads

From Phase 1.4 discrepancy analysis:
- Extract the ~3% of reads that differ
- Trace through pipeline stages manually
- Identify first point of divergence

**Example**:
```bash
# For read "HG002_read_12345" that's paired in BWA-MEM2 but not in FerrousAlign
grep "HG002_read_12345" ferrous_seeds.txt
grep "HG002_read_12345" bwa_seeds.txt  # if available
# Compare seed counts, positions, strand orientation
```

#### 2.3 Known Algorithm Differences

Review code for intentional simplifications made during porting:

**Check these files** (from CLAUDE.md lines 51-73):
- `seeding.rs` (1929 lines) - SMEM extraction, re-seeding, forward-only
- `chaining.rs` (1116 lines) - DP chaining, chain filtering
- `region.rs` (1598 lines) - Extension boundaries, region merging
- `finalization.rs` (1704 lines) - MAPQ calculation, flag assignment

**Search for TODOs/FIXMEs**:
```bash
rg "TODO|FIXME|HACK|WORKAROUND" src/pipelines/linear/{seeding,chaining,region,finalization}.rs
```

### Implementation Tasks

**Task 2.1**: Implement stage-level debug dumping (1 day)
- Add `--debug-stages` CLI flag
- Dump seeds, chains, extensions to human-readable format
- Create comparison scripts

**Task 2.2**: Analyze discrepancies (1-2 days)
- Run on 10K HG002 dataset
- Compare intermediate outputs
- Identify divergence patterns

**Task 2.3**: Fix algorithmic differences (1-2 days)
- Implement missing logic (re-seeding, chain dropping, etc.)
- Adjust tie-breaking to match BWA-MEM2
- Update scoring parameters if needed

**Task 2.4**: Validate fix (1 day)
- Re-run 10K HG002 paired-end test
- Target: 97%+ properly paired
- Ensure no performance regression

**Acceptance Criteria**:
- [ ] Properly paired rate ≥ 97% on 10K HG002 dataset
- [ ] Performance delta ≤ 5% vs Phase 1 baseline
- [ ] All existing tests pass
- [ ] GATK ValidateSamFile still passes

---

## Phase 3: Performance Optimization (Priority #2)

**Duration**: 5-7 days
**Goal**: Achieve 85-90% of BWA-MEM2 throughput

### Current State

From README (lines 194-196):
- x86_64 (Ryzen 9 7900X): ~79% of BWA-MEM2 on 4M read pairs
- Apple Silicon (M3 Max): 36K reads/sec (no BWA-MEM2 comparison)

**Target**: 85-90% of BWA-MEM2 (need ~10-15% improvement)

### Optimization Strategy (Data-Driven)

Use Phase 1.1 profiling data to prioritize:

#### 3.1 Low-Hanging Fruit (2-3 days)

**Batch Size Tuning**:
- Current: Fixed batch sizes in `SoaFastqReader`
- Optimization: Adaptive batching based on read lengths
- Expected gain: 5-10%

**Reduce Allocations**:
- Profile hot paths with `cargo flamegraph`
- Replace `Vec` allocations with pre-allocated buffers
- Use object pools for frequently allocated types
- Expected gain: 3-5%

**SIMD Utilization**:
- Check alignment kernel efficiency (currently ~79% → target 85%+)
- Ensure proper lane utilization in batch processing
- Review SSE/AVX2/NEON code generation
- Expected gain: 2-5%

#### 3.2 Parallel Stage Execution (2-3 days)

**Current**: Sequential stage execution per batch
```rust
let seeds = self.seeder.process(batch, &self.ctx)?;
let chains = self.chainer.process(seeds, &self.ctx)?;
let regions = self.extender.process(chains, &self.ctx)?;
```

**Optimization**: Pipeline parallelism
- Process batch N+1 seeding while batch N is in extension
- Requires stage-level buffering and async coordination
- Expected gain: 5-15% (if I/O bound)

**Implementation**:
```rust
// Use crossbeam channels for stage pipeline
let (seed_tx, seed_rx) = crossbeam::channel::bounded(2);
let (chain_tx, chain_rx) = crossbeam::channel::bounded(2);

// Spawn stage workers
rayon::spawn(move || {
    for batch in batches {
        let seeds = seeder.process(batch)?;
        seed_tx.send(seeds)?;
    }
});

rayon::spawn(move || {
    for seeds in seed_rx {
        let chains = chainer.process(seeds)?;
        chain_tx.send(chains)?;
    }
});
```

**Risk**: Increased complexity, potential for deadlocks
**Mitigation**: Thorough testing, start with single-threaded proof-of-concept

#### 3.3 Cache Optimization (1-2 days)

**Data Locality**:
- Review SoA layouts for cache-friendliness
- Ensure interleaved access patterns align with cache lines
- Prefetch hints in hot loops

**Index Access Patterns**:
- Profile BWT/SA lookups (seeding stage is likely bottleneck)
- Consider index block preloading for common access patterns

**Expected gain**: 2-5%

### Implementation Tasks

**Task 3.1**: Implement batch size tuning (1 day)
**Task 3.2**: Reduce allocations in hot paths (1-2 days)
**Task 3.3**: Improve SIMD utilization (1-2 days)
**Task 3.4**: Add pipeline parallelism (optional, 2-3 days)
**Task 3.5**: Cache optimization (1-2 days)

**Acceptance Criteria**:
- [ ] 4M HG002 paired-end throughput ≥ 85% of BWA-MEM2
- [ ] Properly paired rate unchanged (≥97% from Phase 2)
- [ ] Memory usage unchanged or improved
- [ ] All tests pass

---

## Phase 4: Memory & Threading Optimization (Priority #3/4)

**Duration**: 3-5 days
**Goal**: Reduce peak memory to ~24 GB, improve core utilization

### 4.1 Memory Optimization (2-3 days)

**Current**: ~32 GB peak (from README line 327)

**Strategy** (based on Phase 1.2 profiling):

#### Reduce Batch Sizes (if memory-constrained)
```rust
// Current: Fixed 10K reads/batch
const BATCH_SIZE: usize = 10_000;

// Proposed: Adaptive based on read length
fn compute_batch_size(avg_read_len: usize) -> usize {
    const TARGET_BATCH_BYTES: usize = 100 * 1024 * 1024; // 100 MB
    TARGET_BATCH_BYTES / avg_read_len
}
```

**Expected**: ~20% memory reduction with minimal performance impact

#### Pool/Reuse Allocations
- Implement buffer pools for alignment matrices
- Reuse workspace between batches
- Use arena allocators for temporary structures

**Expected**: ~10-15% memory reduction

#### Lazy Loading
- Don't pre-allocate all stage outputs
- Stream through pipeline stages
- Write SAM records immediately (don't buffer)

**Expected**: ~5-10% memory reduction

**Acceptance Criteria**:
- [ ] Peak memory ≤ 24 GB on 4M HG002 dataset
- [ ] Performance delta ≤ 5% vs Phase 3
- [ ] Properly paired rate unchanged

### 4.2 Threading Optimization (1-2 days)

**Strategy** (based on Phase 1.3 profiling):

#### Better Work Distribution
- Profile Rayon's work-stealing for imbalance
- Consider manual chunking for better load balancing
- Reduce thread synchronization overhead

#### Lock Contention
- Identify hot locks (likely in output writing)
- Use lock-free queues where possible
- Batch output writes to reduce contention

**Acceptance Criteria**:
- [ ] CPU utilization ≥ 90% on all cores
- [ ] Reduced lock contention (measure with perf)
- [ ] Performance improvement ≥ 5%

---

## Testing & Validation Strategy

### Continuous Validation (Every Phase)

**Golden Dataset**: HG002 10K paired-end reads (from GIAB)
```bash
# Run after each phase
cargo build --release
./target/release/ferrous-align mem -t 16 $REF 10k_R1.fq 10k_R2.fq > phase_N.sam

# Validate
samtools flagstat phase_N.sam > phase_N_flagstat.txt
gatk ValidateSamFile -I phase_N.sam -MODE SUMMARY
```

**Metrics to Track**:
- Properly paired rate (target: ≥97%)
- Mapping rate (current: 98.66%)
- Total alignments (20,000 for 10K pairs)
- Duplicate rate (must be 0%)

### Performance Regression Testing

**Benchmark Suite**:
```bash
# Quick check (10K reads, <5 sec)
hyperfine --warmup 3 --runs 10 \
    './target/release/ferrous-align mem -t 16 $REF 10k_R1.fq 10k_R2.fq'

# Full benchmark (4M reads, ~10 min)
/usr/bin/time -v ./target/release/ferrous-align mem -t 16 $REF 4M_R1.fq 4M_R2.fq > /dev/null
```

**Acceptance**: No regression >5% between phases

### Memory Safety

**Valgrind** (single-threaded, small dataset):
```bash
valgrind --leak-check=full --show-leak-kinds=all \
    ./target/release/ferrous-align mem -t 1 $REF 1k_R1.fq 1k_R2.fq > /dev/null
```

**MIRI** (unit tests only):
```bash
cargo +nightly miri test --lib
```

---

## Risk Assessment & Mitigation

### High-Risk Items

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Can't close pairing gap | Medium | High | Detailed comparison with BWA-MEM2, consult C++ source |
| Performance regression during optimization | Medium | Medium | Benchmark after each change, keep known-good commits |
| Memory optimization breaks correctness | Low | Critical | Extensive testing, validate on multiple datasets |
| Pipeline parallelism causes deadlocks | Medium | Medium | Start with proof-of-concept, thorough testing |

### Rollback Strategy

**Per-Phase Checkpoints**:
```bash
# After each successful phase
git tag v0.8.0-phase-N
git push origin v0.8.0-phase-N
```

**Rollback Trigger**: Any of these
- Properly paired rate drops below 94%
- Performance regression >10%
- Memory usage increase >15%
- Test failures that can't be fixed in 1 day

**Rollback Procedure**:
```bash
git checkout v0.8.0-phase-N
# Analyze failure
# Adjust approach
# Re-attempt
```

---

## Documentation Updates

### Update After Each Phase

**README.md**:
- Update "Current Version" section with phase progress
- Update performance numbers
- Update known limitations

**CLAUDE.md**:
- Update status markers
- Add new profiling/debugging commands
- Update known issues

**CHANGELOG.md** (create if doesn't exist):
```markdown
## [0.8.0] - 2025-12-XX

### Added
- Stage-based pipeline architecture
- Detailed performance profiling tools

### Changed
- Pairing accuracy improved from 94.14% to 97%+
- Performance improved from 79% to 85%+ of BWA-MEM2
- Memory usage reduced from 32 GB to 24 GB peak

### Fixed
- [List specific pairing accuracy issues]
```

---

## Timeline & Milestones

### Proposed Schedule (3-4 weeks)

**Week 1** (Dec 4-8):
- [ ] Phase 1: Establish baselines (2 days)
- [ ] Phase 2: Start pairing accuracy investigation (3 days)

**Week 2** (Dec 9-15):
- [ ] Phase 2: Complete pairing accuracy fixes (2 days)
- [ ] Phase 3: Low-hanging fruit optimizations (3 days)

**Week 3** (Dec 16-22):
- [ ] Phase 3: Complete performance optimization (2 days)
- [ ] Phase 4: Memory optimization (3 days)

**Week 4** (Dec 23-29):
- [ ] Phase 4: Threading optimization (2 days)
- [ ] Final validation and documentation (3 days)

**Target Release**: December 27, 2025 (adjust for holidays)

### Milestone Checkpoints

**Checkpoint 1** (End of Week 1):
- Baselines established
- Pairing discrepancies identified
- Go/no-go decision on pairing accuracy approach

**Checkpoint 2** (End of Week 2):
- Pairing accuracy ≥97%
- Initial performance improvements showing
- Go/no-go decision on pipeline parallelism

**Checkpoint 3** (End of Week 3):
- Performance target achieved (85%+)
- Memory reduction showing progress
- Prep for final release

**Final Release** (End of Week 4):
- All acceptance criteria met
- Documentation complete
- Release notes published

---

## Post-v0.8.0 Roadmap Preview

### v0.9.0 (Next Release)
From README lines 330-334:
- Algorithm refinements (re-seeding, chain dropping)
- Production-ready index building validation
- Broader dataset validation beyond HG002

### v1.0.0 (Production Ready)
From README lines 336-340:
- 100% feature parity with BWA-MEM2
- BAM/CRAM output support
- Performance matching BWA-MEM2
- Extensive real-world validation

---

## References

- README.md lines 324-328 - Public v0.8.0 roadmap
- Pipeline_Restructure_v0.8_Plan.md - Completed architectural work
- SOA_End_to_End.md - SoA architecture with hybrid discovery
- CLAUDE.md - Developer guidelines and file size targets
- 2025-12-02-BENCHMARKS.md - Current performance baselines

---

## Appendix A: Profiling Commands Reference

### Performance Profiling
```bash
# Flame graph
cargo flamegraph -- mem -t 16 $REF R1.fq R2.fq

# perf record/report
perf record -F 999 -g ./target/release/ferrous-align mem -t 16 $REF R1.fq R2.fq
perf report --stdio

# Stage-level timing (add to code)
use std::time::Instant;
let t = Instant::now();
// ... stage work ...
eprintln!("Stage XYZ: {:.2}ms", t.elapsed().as_secs_f64() * 1000.0);
```

### Memory Profiling
```bash
# Massif
valgrind --tool=massif ./target/release/ferrous-align mem -t 1 $REF R1.fq R2.fq
ms_print massif.out.* > memory_profile.txt

# Heaptrack (Linux)
heaptrack ./target/release/ferrous-align mem -t 16 $REF R1.fq R2.fq
heaptrack_gui heaptrack.*.gz
```

### Threading Profiling
```bash
# CPU utilization
perf stat -e cycles,instructions,context-switches \
    ./target/release/ferrous-align mem -t 16 $REF R1.fq R2.fq

# Lock contention
perf record -e syscalls:sys_enter_futex -g ./target/release/ferrous-align mem -t 16 $REF R1.fq R2.fq
```

---

## Appendix B: Comparison Scripts

### Compare Pairing Decisions
```bash
#!/bin/bash
# compare_pairing.sh

BWA_SAM=$1
FERROUS_SAM=$2

# Extract properly paired read names
samtools view -f 2 $BWA_SAM | cut -f1 | sort -u > bwa_paired.txt
samtools view -f 2 $FERROUS_SAM | cut -f1 | sort -u > ferrous_paired.txt

# Find differences
echo "Paired in BWA-MEM2 but not FerrousAlign:"
comm -23 bwa_paired.txt ferrous_paired.txt | wc -l

echo "Paired in FerrousAlign but not BWA-MEM2:"
comm -13 bwa_paired.txt ferrous_paired.txt | wc -l

# Clean up
rm bwa_paired.txt ferrous_paired.txt
```

### Compare Flagstat
```bash
#!/bin/bash
# compare_flagstat.sh

BWA_SAM=$1
FERROUS_SAM=$2

echo "=== BWA-MEM2 ==="
samtools flagstat $BWA_SAM

echo ""
echo "=== FerrousAlign ==="
samtools flagstat $FERROUS_SAM
```

---

*Document Version: 1.0*
*Created: 2025-12-03*
*Author: Claude Code*
*Status: Ready for Review*
